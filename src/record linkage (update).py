# src/main.py
import pandas as pd
import re
from rapidfuzz import fuzz, process
from utils.cleaning import clean_name
from utils.matching import match_variant_to_reference

def main():
primary = pd.read_csv("primary.csv")     # åŒ…å«: ID, NAME, TYPE
alternate = pd.read_csv("alternate.csv") # åŒ…å«: ID, NAME
test = pd.read_csv("test_01.csv")           # åŒ…å«: ID, VARIANT
    test = pd.read_csv("test_01.csv")        # åŒ…å«: ID, VARIANT


# åŠ å…¥æ¥æºæ ‡æ³¨
primary['SOURCE'] = 'primary'
alternate['SOURCE'] = 'alternate'










# åº”ç”¨æ¸…æ´—
primary['CLEAN_NAME'] = primary['NAME'].apply(clean_name)
alternate['CLEAN_NAME'] = alternate['NAME'].apply(clean_name)
test['CLEAN_NAME'] = test['VARIANT'].apply(clean_name)

# åˆå¹¶ primary å’Œ alternate æˆä¸€ä¸ª reference åŒ¹é…åº“
reference = pd.concat([
    primary[['ID', 'CLEAN_NAME']],
    alternate[['ID', 'CLEAN_NAME']]
]).drop_duplicates().reset_index(drop=True)
















# åªä¿ç•™300æ¡éšæœºæ ·æœ¬ï¼ˆå›ºå®š random_state å¯å¤ç°ï¼‰
test_sampled = test.sample(n=300, random_state=42).reset_index(drop=True)

# å¯¹æ¯ä¸ª test åç§°åšåŒ¹é…
test_sampled[['MATCHED_ID', 'SCORE']] = test_sampled['CLEAN_NAME'].apply(
    lambda x: match_variant_to_reference(x, reference)
)

thres = 80.0

test_sampled['CORRECT'] = test_sampled['ID'] == test_sampled['MATCHED_ID']



    # æŸ¥çœ‹åŒ¹é…ç»“æœ
print(test_sampled[['VARIANT', 'MATCHED_ID', 'SCORE', 'ID', 'CORRECT']])

print(f"åŒ¹é…å‡†ç¡®ç‡ï¼ˆ300æ¡æ ·æœ¬ï¼‰: {test_sampled['CORRECT'].mean():.2%}")


# åŒ¹é…æ­£ç¡®
correct = test_sampled['MATCHED_ID'] == test_sampled['ID']
# ç½®ä¿¡åº¦é€šè¿‡
confident = test_sampled['SCORE'] >= thres

# åˆ†ç±»å››ç§æƒ…å†µï¼š
TP = ((correct) & (confident)).sum()
FP = ((~correct) & (confident)).sum()
FN = ((~correct) & (~confident)).sum()
TN = ((correct) & (~confident)).sum()  # å¯é€‰ç»Ÿè®¡

print(f"âœ… True Positives  (æ­£ç¡®åŒ¹é…ï¼Œscoreé«˜): {TP}")
print(f"âŒ False Positives (é”™è¯¯åŒ¹é…ï¼Œscoreé«˜): {FP}")
print(f"âŒ False Negatives (æ­£ç¡®åŒ¹é…ï¼Œä½†scoreä½è¢«æ‹’ç»): {FN}")
print(f"âœ… True Negatives  (é”™è¯¯åŒ¹é…ï¼Œscoreä½è¢«æ‹’ç»): {TN}")

precision = TP / (TP + FP) if TP + FP > 0 else 0
recall    = TP / (TP + FN) if TP + FN > 0 else 0
f1        = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0
accuracy  = (TP + TN) / len(test_sampled)

print(f"\nğŸ¯ Precision: {precision:.2%}")
print(f"ğŸ¯ Recall:    {recall:.2%}")
print(f"ğŸ¯ F1 Score:  {f1:.2%}")
print(f"ğŸ¯ Accuracy (åŒ…å«æ‹’ç»): {accuracy:.2%}")





















if __name__ == "__main__":
    main()
